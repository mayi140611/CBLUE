{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb61da5",
   "metadata": {},
   "source": [
    "# prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b6415e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3473884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cea6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39129b",
   "metadata": {},
   "source": [
    "# CMeEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62a5a56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5525f83fe949468b53887fe6c23beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/19.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a12348ed29346468d1b3248ba42c2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4d3d6fd0aa41fe90554d978c4e6082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/107k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47398f3137194d078341df94437795d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/263k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7310717663a94cab947b8b0c4cab2601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9031866c8338421d83d3a7335d02b215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"hfl/chinese-bert-wwm-ext\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9457cef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ea0f97b23a4552ad4028cd0ba817ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/393M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-bert-wwm-ext were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel \n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "780da600",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('data/model_data/chinese-bert-wwm-ext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b7795ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/model_data/chinese-bert-wwm-ext/tokenizer_config.json',\n",
       " 'data/model_data/chinese-bert-wwm-ext/special_tokens_map.json',\n",
       " 'data/model_data/chinese-bert-wwm-ext/vocab.txt',\n",
       " 'data/model_data/chinese-bert-wwm-ext/added_tokens.json',\n",
       " 'data/model_data/chinese-bert-wwm-ext/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('data/model_data/chinese-bert-wwm-ext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20e7d81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 15 09:07:51 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   69C    P0    65W /  70W |   8751MiB / 15109MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   28C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4            Off  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   70C    P0    64W /  70W |   8282MiB / 15109MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla T4            Off  | 00000000:00:09.0 Off |                    0 |\n",
      "| N/A   29C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ad5bf17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running\n",
      "06/14/2022 09:25:16 - INFO - root -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, data_dir='CBLUEDatasets', device=device(type='cuda'), do_predict=False, do_train=True, earlystop_patience=100, epochs=5, eval_batch_size=16, learning_rate=3e-05, logging_steps=200, max_grad_norm=0.0, max_length=128, model_dir='data/model_data', model_name='chinese-bert-wwm-ext', model_type='bert', output_dir='data/output/ee/chinese-bert-wwm-ext', result_output_dir='data/result_output', save_steps=200, seed=2021, task_name='ee', train_batch_size=16, warmup_proportion=0.1, weight_decay=0.01)\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at data/model_data/chinese-bert-wwm-ext and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "06/14/2022 09:25:26 - INFO - root -   ***** Running training *****\n",
      "06/14/2022 09:25:26 - INFO - root -   Num samples 15000\n",
      "06/14/2022 09:25:26 - INFO - root -   Num epochs 5\n",
      "06/14/2022 09:25:26 - INFO - root -   Num training steps 4690\n",
      "06/14/2022 09:25:26 - INFO - root -   Num warmup steps 469\n",
      "[Training] 200/938 [=====>........................] - ETA: 4:01  loss: 0.5795 \n",
      "06/14/2022 09:26:32 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:26:32 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:27:09 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.7330736214559621 - recall: 0.7330736214559621 - f1 score: 0.7330736214559622\n",
      "06/14/2022 09:27:09 - INFO - root -   Saving models checkpoint to data/output/ee/chinese-bert-wwm-ext/checkpoint-200\n",
      "[Training] 400/938 [===========>..................] - ETA: 3:51  loss: 0.6415 \n",
      "06/14/2022 09:28:18 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:28:18 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:28:56 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.7926904574944157 - recall: 0.7926904574944157 - f1 score: 0.7926904574944157\n",
      "06/14/2022 09:28:57 - INFO - root -   Saving models checkpoint to data/output/ee/chinese-bert-wwm-ext/checkpoint-400\n",
      "[Training] 600/938 [==================>...........] - ETA: 2:38  loss: 0.3888 \n",
      "06/14/2022 09:30:08 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:30:08 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:30:48 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.7926828338580937 - recall: 0.7926828338580937 - f1 score: 0.7926828338580938\n",
      "06/14/2022 09:30:48 - INFO - root -   Earlystopper counter: 1 out of 100\n",
      "[Training] 800/938 [========================>.....] - ETA: 1:07  loss: 0.6784 \n",
      "06/14/2022 09:31:59 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:31:59 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:32:38 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.797340875650868 - recall: 0.797340875650868 - f1 score: 0.797340875650868\n",
      "06/14/2022 09:32:39 - INFO - root -   Saving models checkpoint to data/output/ee/chinese-bert-wwm-ext/checkpoint-800\n",
      "[Training] 62/938 [>.............................] - ETA: 5:12  loss: 0.3632 1 \n",
      "06/14/2022 09:33:50 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:33:50 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:34:29 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.796193518384399 - recall: 0.796193518384399 - f1 score: 0.796193518384399\n",
      "06/14/2022 09:34:29 - INFO - root -   Earlystopper counter: 1 out of 100\n",
      "[Training] 262/938 [=======>......................] - ETA: 5:45  loss: 0.4057  \n",
      "06/14/2022 09:35:42 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:35:42 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:36:22 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8060356328761693 - recall: 0.8060356328761693 - f1 score: 0.8060356328761693\n",
      "06/14/2022 09:36:22 - INFO - root -   Saving models checkpoint to data/output/ee/chinese-bert-wwm-ext/checkpoint-1200\n",
      "[Training] 462/938 [=============>................] - ETA: 4:13  loss: 0.4425 \n",
      "06/14/2022 09:37:34 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:37:34 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:38:13 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8060851865122626 - recall: 0.8060851865122626 - f1 score: 0.8060851865122626\n",
      "06/14/2022 09:38:14 - INFO - root -   Saving models checkpoint to data/output/ee/chinese-bert-wwm-ext/checkpoint-1400\n",
      "[Training] 662/938 [====================>.........] - ETA: 2:29  loss: 0.4778 \n",
      "06/14/2022 09:39:26 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:39:26 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:40:06 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8043774919761227 - recall: 0.8043774919761227 - f1 score: 0.8043774919761227\n",
      "06/14/2022 09:40:06 - INFO - root -   Earlystopper counter: 1 out of 100\n",
      "[Training] 862/938 [==========================>...] - ETA: 41s  loss: 1.0221  \n",
      "06/14/2022 09:41:18 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:41:18 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:41:58 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.801232741993276 - recall: 0.801232741993276 - f1 score: 0.801232741993276\n",
      "06/14/2022 09:41:58 - INFO - root -   Earlystopper counter: 2 out of 100\n",
      "[Training] 124/938 [==>...........................] - ETA: 4:52  loss: 0.3748  \n",
      "06/14/2022 09:43:09 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:43:09 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:43:49 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8084103955904888 - recall: 0.8084103955904888 - f1 score: 0.8084103955904888\n",
      "06/14/2022 09:43:49 - INFO - root -   Saving models checkpoint to data/output/ee/chinese-bert-wwm-ext/checkpoint-2000\n",
      "[Training] 324/938 [=========>....................] - ETA: 4:57  loss: 0.3894 \n",
      "06/14/2022 09:45:02 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:45:02 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:45:42 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8037523537977145 - recall: 0.8037523537977145 - f1 score: 0.8037523537977145\n",
      "06/14/2022 09:45:42 - INFO - root -   Earlystopper counter: 1 out of 100\n",
      "[Training] 524/938 [===============>..............] - ETA: 3:32  loss: 0.2713 \n",
      "06/14/2022 09:46:54 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:46:54 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:47:33 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8092299364951094 - recall: 0.8092299364951094 - f1 score: 0.8092299364951093\n",
      "06/14/2022 09:47:34 - INFO - root -   Saving models checkpoint to data/output/ee/chinese-bert-wwm-ext/checkpoint-2400\n",
      "[Training] 724/938 [======================>.......] - ETA: 1:52  loss: 0.2451 \n",
      "06/14/2022 09:48:46 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:48:46 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:49:25 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8104306592158328 - recall: 0.8104306592158328 - f1 score: 0.8104306592158329\n",
      "06/14/2022 09:49:25 - INFO - root -   Saving models checkpoint to data/output/ee/chinese-bert-wwm-ext/checkpoint-2600\n",
      "[Training] 924/938 [============================>.] - ETA: 7s  loss: 0.2944   \n",
      "06/14/2022 09:50:38 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:50:38 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:51:18 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.809298549222008 - recall: 0.809298549222008 - f1 score: 0.809298549222008\n",
      "06/14/2022 09:51:18 - INFO - root -   Earlystopper counter: 1 out of 100\n",
      "[Training] 186/938 [====>.........................] - ETA: 4:29  loss: 0.3453  \n",
      "06/14/2022 09:52:29 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:52:29 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:53:09 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8077623865031143 - recall: 0.8077623865031143 - f1 score: 0.8077623865031143\n",
      "06/14/2022 09:53:09 - INFO - root -   Earlystopper counter: 2 out of 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] 386/938 [===========>..................] - ETA: 4:14  loss: 0.2736 \n",
      "06/14/2022 09:54:21 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:54:21 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:55:00 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8063672610561786 - recall: 0.8063672610561786 - f1 score: 0.8063672610561786\n",
      "06/14/2022 09:55:00 - INFO - root -   Earlystopper counter: 3 out of 100\n",
      "[Training] 586/938 [=================>............] - ETA: 2:54  loss: 0.1987 \n",
      "06/14/2022 09:56:13 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:56:13 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:56:53 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.807156307415511 - recall: 0.807156307415511 - f1 score: 0.807156307415511\n",
      "06/14/2022 09:56:53 - INFO - root -   Earlystopper counter: 4 out of 100\n",
      "[Training] 786/938 [========================>.....] - ETA: 1:17  loss: 0.2431 \n",
      "06/14/2022 09:58:05 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:58:05 - INFO - root -   Num samples 5000\n",
      "06/14/2022 09:58:44 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.806851361962629 - recall: 0.806851361962629 - f1 score: 0.806851361962629\n",
      "06/14/2022 09:58:44 - INFO - root -   Earlystopper counter: 5 out of 100\n",
      "[Training] 48/938 [>.............................] - ETA: 5:19  loss: 0.2487 6 \n",
      "06/14/2022 09:59:56 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 09:59:56 - INFO - root -   Num samples 5000\n",
      "06/14/2022 10:00:36 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8073850165051727 - recall: 0.8073850165051727 - f1 score: 0.8073850165051727\n",
      "06/14/2022 10:00:36 - INFO - root -   Earlystopper counter: 6 out of 100\n",
      "[Training] 248/938 [======>.......................] - ETA: 6:01  loss: 0.2541  \n",
      "06/14/2022 10:01:48 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 10:01:48 - INFO - root -   Num samples 5000\n",
      "06/14/2022 10:02:27 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8074498174139101 - recall: 0.8074498174139101 - f1 score: 0.8074498174139101\n",
      "06/14/2022 10:02:27 - INFO - root -   Earlystopper counter: 7 out of 100\n",
      "[Training] 448/938 [=============>................] - ETA: 4:23  loss: 0.1858 \n",
      "06/14/2022 10:03:39 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 10:03:39 - INFO - root -   Num samples 5000\n",
      "06/14/2022 10:04:18 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8080520846833522 - recall: 0.8080520846833522 - f1 score: 0.8080520846833522\n",
      "06/14/2022 10:04:18 - INFO - root -   Earlystopper counter: 8 out of 100\n",
      "[Training] 648/938 [===================>..........] - ETA: 2:37  loss: 0.3041 \n",
      "06/14/2022 10:05:31 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 10:05:31 - INFO - root -   Num samples 5000\n",
      "06/14/2022 10:06:10 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8073011565056301 - recall: 0.8073011565056301 - f1 score: 0.8073011565056301\n",
      "06/14/2022 10:06:10 - INFO - root -   Earlystopper counter: 9 out of 100\n",
      "[Training] 848/938 [==========================>...] - ETA: 49s  loss: 0.2517  \n",
      "06/14/2022 10:07:22 - INFO - root -   ***** Running evaluation *****\n",
      "06/14/2022 10:07:22 - INFO - root -   Num samples 5000\n",
      "06/14/2022 10:08:02 - INFO - root -   ee-chinese-bert-wwm-ext precision: 0.8072249201424095 - recall: 0.8072249201424095 - f1 score: 0.8072249201424095\n",
      "06/14/2022 10:08:02 - INFO - root -   Earlystopper counter: 10 out of 100\n",
      "[Training] 938/938 [==============================] 571.0ms/step  loss: 0.2810 06/14/2022 10:08:34 - INFO - root -   Training Stop! The best step 2600: 0.8104306592158329\n",
      "06/14/2022 10:08:35 - INFO - root -   Saving models checkpoint to data/output/ee/chinese-bert-wwm-ext\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=3  bash examples/run_ee.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e4dc228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running\n",
      "06/14/2022 11:26:57 - INFO - root -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, data_dir='CBLUEDatasets', device=device(type='cuda'), do_predict=True, do_train=False, earlystop_patience=2, epochs=3, eval_batch_size=32, learning_rate=5e-05, logging_steps=10, max_grad_norm=1.0, max_length=128, model_dir='data/model_data', model_name='chinese-bert-wwm-ext', model_type='bert', output_dir='data/output/ee/chinese-bert-wwm-ext', result_output_dir='data/result_output', save_steps=1000, seed=2021, task_name='ee', train_batch_size=8, warmup_proportion=0.1, weight_decay=0.01)\n",
      "06/14/2022 11:27:02 - INFO - root -   ***** Running prediction *****\n",
      "06/14/2022 11:27:02 - INFO - root -   Num samples 3000\n",
      "[Prediction] 94/94 [==============================] 203.4ms/step"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=3  bash examples/run_ee.sh predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a0341",
   "metadata": {},
   "source": [
    "# CMeIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "694e612d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=3  bash examples/run_ie.sh\n",
    "\n",
    "# [Training] 400/449 [=========================>....] - ETA: 39s  loss: 0.0755  \n",
    "# 06/14/2022 20:18:25 - INFO - root -   ***** Running evaluation *****\n",
    "# 06/14/2022 20:18:25 - INFO - root -   Num samples 3585\n",
    "# 06/14/2022 20:19:12 - INFO - root -   ie-checkpoint-3000 f1 score: 0.8953149059389314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea2d108d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running\n",
      "06/15/2022 10:13:26 - INFO - root -   Training ER model...\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "06/15/2022 10:13:31 - INFO - root -   ***** Running training *****\n",
      "06/15/2022 10:13:31 - INFO - root -   Num samples 14339\n",
      "06/15/2022 10:13:31 - INFO - root -   Num epochs 1\n",
      "06/15/2022 10:13:31 - INFO - root -   Num training steps 449\n",
      "06/15/2022 10:13:31 - INFO - root -   Num warmup steps 44\n",
      "[Training] 200/449 [============>.................] - ETA: 2:44  loss: 0.2465 \n",
      "06/15/2022 10:15:44 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 10:15:44 - INFO - root -   Num samples 3585\n",
      "06/15/2022 10:16:31 - INFO - root -   ie-chinese-bert-wwm-ext f1 score: 0.8246199385390132\n",
      "06/15/2022 10:16:32 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-200\n",
      "[Training] 400/449 [=========================>....] - ETA: 39s  loss: 0.1753  \n",
      "06/15/2022 10:18:51 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 10:18:51 - INFO - root -   Num samples 3585\n",
      "06/15/2022 10:19:40 - INFO - root -   ie-chinese-bert-wwm-ext f1 score: 0.8537684861784975\n",
      "06/15/2022 10:19:41 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-400\n",
      "[Training] 449/449 [==============================] 899.8ms/step  loss: 0.1518 06/15/2022 10:20:15 - INFO - root -   Training Stop! The best step 400: 0.8537684861784975\n",
      "06/15/2022 10:20:17 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/er\n",
      "06/15/2022 10:20:17 - INFO - root -   Training RE model...\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "06/15/2022 10:20:20 - INFO - root -   ***** Running training *****\n",
      "06/15/2022 10:20:20 - INFO - root -   Num samples 64618\n",
      "06/15/2022 10:20:20 - INFO - root -   Num epochs 1\n",
      "06/15/2022 10:20:20 - INFO - root -   Num training steps 2020\n",
      "06/15/2022 10:20:20 - INFO - root -   Num warmup steps 202\n",
      "[Training] 200/2020 [=>............................] - ETA: 22:03  loss: 1.7675 \n",
      "06/15/2022 10:22:45 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 10:22:45 - INFO - root -   Num samples 15218\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/15/2022 10:24:49 - INFO - root -   ie-chinese-bert-wwm-ext precision: 0.20754436966680875 - recall: 0.1634204231649407 - f1 score: 0.1584516603368045\n",
      "06/15/2022 10:24:50 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-200\n",
      "[Training] 400/2020 [====>.........................] - ETA: 28:13  loss: 0.8211 \n",
      "06/15/2022 10:27:18 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 10:27:18 - INFO - root -   Num samples 15218\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/15/2022 10:29:23 - INFO - root -   ie-chinese-bert-wwm-ext precision: 0.3328969747042218 - recall: 0.2926903366897734 - f1 score: 0.28064976483325854\n",
      "06/15/2022 10:29:24 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-400\n",
      "[Training] 600/2020 [=======>......................] - ETA: 27:26  loss: 1.3339 \n",
      "06/15/2022 10:31:56 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 10:31:56 - INFO - root -   Num samples 15218\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/15/2022 10:34:01 - INFO - root -   ie-chinese-bert-wwm-ext precision: 0.4249425643259999 - recall: 0.3951489134429567 - f1 score: 0.38484373804382654\n",
      "06/15/2022 10:34:02 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-600\n",
      "[Training] 800/2020 [==========>...................] - ETA: 24:39  loss: 0.5136 \n",
      "06/15/2022 10:36:30 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 10:36:30 - INFO - root -   Num samples 15218\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/15/2022 10:38:36 - INFO - root -   ie-chinese-bert-wwm-ext precision: 0.5610522812357418 - recall: 0.4573318995260658 - f1 score: 0.4740359408107375\n",
      "06/15/2022 10:38:36 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-800\n",
      "[Training] 1000/2020 [=============>................] - ETA: 21:09  loss: 0.8940 \n",
      "06/15/2022 10:41:05 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 10:41:05 - INFO - root -   Num samples 15218\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/15/2022 10:43:10 - INFO - root -   ie-chinese-bert-wwm-ext precision: 0.6037760194291674 - recall: 0.5181414129286575 - f1 score: 0.5314110312376833\n",
      "06/15/2022 10:43:10 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-1000\n",
      "[Training] 1200/2020 [================>.............] - ETA: 17:17  loss: 0.6165 \n",
      "06/15/2022 10:45:39 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 10:45:39 - INFO - root -   Num samples 15218\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/15/2022 10:47:43 - INFO - root -   ie-chinese-bert-wwm-ext precision: 0.6313385301321126 - recall: 0.5513638605423401 - f1 score: 0.5710490289009066\n",
      "06/15/2022 10:47:43 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-1200\n",
      "[Training] 1400/2020 [===================>..........] - ETA: 13:13  loss: 0.9775 \n",
      "06/15/2022 10:50:11 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 10:50:11 - INFO - root -   Num samples 15218\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/15/2022 10:52:17 - INFO - root -   ie-chinese-bert-wwm-ext precision: 0.6342828369954506 - recall: 0.5751408831973649 - f1 score: 0.5911133661082258\n",
      "06/15/2022 10:52:17 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-1400\n",
      "[Training] 1600/2020 [======================>.......] - ETA: 9:02  loss: 0.7692  \n",
      "06/15/2022 10:54:46 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 10:54:46 - INFO - root -   Num samples 15218\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/15/2022 10:56:52 - INFO - root -   ie-chinese-bert-wwm-ext precision: 0.6303108004906834 - recall: 0.596725241979696 - f1 score: 0.5989389100546223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/15/2022 10:56:53 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-1600\n",
      "[Training] 1800/2020 [=========================>....] - ETA: 4:46  loss: 0.7438 \n",
      "06/15/2022 10:59:24 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 10:59:24 - INFO - root -   Num samples 15218\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/15/2022 11:01:30 - INFO - root -   ie-chinese-bert-wwm-ext precision: 0.6684676525467006 - recall: 0.5998055842323413 - f1 score: 0.6141235683084485\n",
      "06/15/2022 11:01:30 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-1800\n",
      "[Training] 2000/2020 [============================>.] - ETA: 26s  loss: 0.8556  \n",
      "06/15/2022 11:04:00 - INFO - root -   ***** Running evaluation *****\n",
      "06/15/2022 11:04:00 - INFO - root -   Num samples 15218\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/15/2022 11:06:05 - INFO - root -   ie-chinese-bert-wwm-ext precision: 0.6533710254466468 - recall: 0.6070657800509844 - f1 score: 0.619559086343489\n",
      "06/15/2022 11:06:05 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/checkpoint-2000\n",
      "[Training] 2020/2020 [==============================] 1.4s/step  loss: 1.0352  06/15/2022 11:06:20 - INFO - root -   Training Stop! The best step 2000: 0.619559086343489\n",
      "06/15/2022 11:06:22 - INFO - root -   Saving models checkpoint to data/output/ie/chinese-bert-wwm-ext/re\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=3  bash examples/run_ie.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "beb8f3ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running\n",
      "06/15/2022 11:06:30 - INFO - root -   ***** Running prediction *****\n",
      "06/15/2022 11:06:30 - INFO - root -   Num samples 4482\n",
      "[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65]]\n",
      "[(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12), (13, 13), (14, 14), (15, 15), (16, 16), (17, 17), (18, 18), (19, 19), (20, 20), (21, 21), (22, 22), (23, 23), (24, 24), (25, 25), (26, 26), (27, 27), (28, 28), (29, 29), (30, 30), (31, 31), (32, 32), (33, 33), (34, 34), (35, 35), (36, 36), (37, 37), (38, 38), (39, 39), (40, 40), (41, 41), (42, 42), (43, 43), (44, 44), (45, 45), (46, 46), (47, 47), (48, 48), (49, 49), (50, 50), (51, 51), (52, 52), (53, 53), (54, 54), (55, 55), (56, 56), (57, 57), (58, 58), (59, 59), (60, 60), (61, 61), (62, 62), (63, 63), (64, 64), (65, 65), (66, 66)]\n",
      "Traceback (most recent call last):\n",
      "  File \"baselines/run_ie.py\", line 221, in <module>\n",
      "    main()\n",
      "  File \"baselines/run_ie.py\", line 196, in main\n",
      "    trainer.predict(test_dataset, model)\n",
      "  File \"./cblue/trainer/train.py\", line 1486, in predict\n",
      "    text, text_mapping)\n",
      "  File \"./cblue/data/data_process.py\", line 355, in extract_arg\n",
      "    start_split = text_mapping[k[0]]\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=3  bash examples/run_ie.sh predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af795d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
